# ex: set syntax=python:					-*-python-*-

# This is the buildmaster config file for the Unified Build Candidate
# Project for LinuxCNC. It must be installed as 'master.cfg' in your
# buildmaster's base directory.
# 
# Author: Kent A Reed, based on master.cfg.sample file included in
# BuildBot distro
#
# Version 1 (I don't like 'point' versions for configuration files):
#
# In this version, everything is done explicitly. No cleverness with
# variables, builders, with Python scripts, with most anything. Mostly
# I ignored the "fleet" of predefined buildStep Classes/commands and
# used shell scripts.
#

####### VARIABLES

# Debug flag (True or False)
debug = True
if debug:
    from pprint import pprint

####### CONFIG

# Read in host and builder configuration from 'config.yaml'
#
# See 'config.yaml.sample' for notes about format
#
import os, yaml
try:
    basedir
    outside_buildbot = False
except:
    # basedir not defined; this script not called from buildbot
    basedir = os.path.dirname(os.path.realpath(__file__))
    outside_buildbot = True
configs = \
    yaml.load(open(os.path.join(basedir,'config.yaml'),'r').read())

# get defaults
builder_defaults = configs['builders'].pop('DEFAULT',{})
slave_defaults = configs['slaves'].pop("DEFAULT",{})


# Init the dictionary that the buildmaster pays attention to. We
# also use a shorter alias to save typing.

c = BuildmasterConfig = {
    'slaves' : [],
    'schedulers' : [],
    'change_source' : [],
    'builders' : [],
    'status' : [],
    }

# Set the umask
if configs['global'].has_key('umask'):
    if debug:
        print "Setting umask to %s" % oct(configs['global']['umask'])
    os.umask(configs['global']['umask'])

####### ENUMERATIONS

class Enumerations(object):

    def __init__(self,val):
        self.exclude = val.pop('exclude',[])
        self.orderings = val.pop('orderings',{})
        self.val = val

    def permutations(self,order,top=True):
        if isinstance(order,str):
            # look up ordering
            order = self.orderings[order]
        elif order is None:
            return [{}]
        if top is True:
            # temp copy of ordered param list
            orig_order = order
            order = list(order)
        enum_key = order.pop(0)
        if order:
            # more params left in list; recurse again for "sub_permutations"
            sub_enum_list = self.permutations(order,False)
        else:
            sub_enum_list = [{}]
        if enum_key.startswith('pass:'):
            # pass through
            this_enum = [ enum_key ]
        else:
            this_enum = self.val[enum_key]
        enum_list = []
        for val in this_enum:
            for sub_enum in sub_enum_list:
                if enum_key.startswith('pass:'):
                    enum = { enum_key : '%(' + enum_key[5:] + ')s' }
                else:
                    enum = { enum_key : val }
                if sub_enum: enum.update(sub_enum)
                if not top or not self.is_excluded(enum,orig_order):
                    enum_list.append(enum)
        return enum_list

    def sub_permutations(self,permutation,ordering):
        # if a permutation has any 'pass:' keys left, expand them with
        # ordering
        clean_p = {}
        ptemp = permutation.copy()
        # clean existing keys out of permutation
        order = dict(zip(self.orderings[ordering],range(len(ordering))))
        for key in self.orderings[ordering]:
            if permutation.has_key(key):
                clean_p[key] = permutation[key]
                order.pop(key)
        perms = self.permutations(order.keys())
        res = []
        for i in perms:
            h = clean_p.copy()
            h.update(i)
            if not self.is_excluded(h,self.orderings[ordering]):
                res.append(h)
        return res

    def is_excluded(self,enum,order):
        format_str = '-'.join(['%(' + i + ')s' for i in order \
                                   if not i.startswith('pass:')])
        return format_str % enum in self.exclude

    def expand_item(self,item,permutations,extra_keys=[]):
        # given a hash, return list of hashes filled out with permutations
        res = []
        for p in permutations:
            newitem = item.copy()
            # copy the properties dict; add enumerated params
            newitem['properties'] = item.get('properties',{}).copy()
            for key,val in p.items():
                if not val.startswith('%('):
                    newitem['properties'][key] = val
            # copy the selectors dict; fill in any %(templates)s
            if newitem.has_key('selectors'):
                newitem['selectors'] = newitem['selectors'].copy()
                for key in newitem['selectors']:
                    newitem['selectors'][key] = \
                        newitem['selectors'][key] % p
            # fill out any attributes listed in extra_keys
            for key in extra_keys:
                if newitem.get('enumerate-attrs',{}).has_key(key):
                    # enumerate-attrs expansion below will handle this
                    continue
                elif isinstance(newitem[key],list):
                    # assume list of strings
                    newitem[key] = list(newitem[key])
                    for i in range(len(newitem[key])):
                        newitem[key][i] = newitem[key][i] % p
                else:
                    # assume string
                    newitem[key] = str(newitem[key]) % p
            # handle 'enumerate-attrs' params
            for (attr,ordering) in newitem.pop('enumerate-attrs',{}).items():
                valhash = {}  # new list from dict keys: guaranteed unique
                for name in newitem[attr]:
                    for expanded_name in self.expand_name(
                        name, self.sub_permutations(p,ordering)):
                        valhash[expanded_name] = 1
                newitem[attr] = valhash.keys()
            # add processed item to result list
            res.append(newitem)
        return res
        
    def expand_name(self,name,permutations):
        # given a string pattern, return list of strings filled out
        # with permutations
        uniquify = {}
        res = []
        for p in permutations:
            expanded = name % p
            if not uniquify.has_key(expanded):
                uniquify[name % p] = 1
                res.append(expanded)
        return res
        
    def expand_list(self,itemlist,extra_keys=[]):
        # given a list of items, return new list with each item expanded
        res = []
        for item in itemlist:
            item_copy = item.copy()
            if not item.has_key('enumerate') and \
                    not item.has_key('enumerate-attrs'):
                # no enumeration
                res.append(item.copy())
            else:
                if not item.has_key('enumerate'):
                    permutations = [{}]   # dummy permutation
                else:
                    permutations = \
                        self.permutations(item_copy.pop('enumerate'))
                res.extend(
                    self.expand_item(item_copy,permutations,extra_keys))
        return res

    def expand_hash(self,itemhash,extra_keys=[]):
        # given a hash of items, return new hash with each key:value
        # pair expanded
        res = itemhash.copy()
        for key in itemhash:
            if not itemhash[key].has_key('enumerate'):
                # no enumeration; do nothing
                continue
            item_copy = res.pop(key).copy()
            permutations = self.permutations(item_copy.pop('enumerate'))
            names = self.expand_name(key,permutations)
            items = self.expand_item(item_copy,permutations,extra_keys)
            res.update(dict(zip(names,items)))
        return res
                

enumerations = Enumerations(configs.pop('enumerations',{}))

# schedulers and builders may be enumerated
configs['schedulers'] = enumerations.expand_hash(configs['schedulers'])
configs['builders'] = enumerations.expand_hash(configs['builders'])
# build factory steps may be enumerated
for bf in configs['buildfactories'].values():
    bf['steps'] = enumerations.expand_list(bf['steps'],
                                           ['name','schedulerNames'])

####### BUILDSLAVES

# The 'slaves' list defines the set of recognized buildslaves. Each
# element is a BuildSlave object, specifying a unique slave name and
# password.  The same slave name and password must be configured on
# the slave.
#
# note: max_builds= is used to limit the cpu burden. The host may be
# capable of more
#
# note: no harm to define some "future" slaves which don't exist yet

from buildbot.buildslave import BuildSlave
for (host, params) in configs['slaves'].items():

    # Copy the slave_defaults dict and merge parameters
    slave_params = slave_defaults.copy()
    slave_params.update(params)

    # 'password' is a positional parameter; remove from params dict
    secret = slave_params.pop('secret',None)

    # remove 'selectors' used to match builders
    slave_params.pop('selectors',None)

    if debug:
        print("Adding slave, name='%s', secret='%s[...]'" % (host,secret[:3]))

    # Create the build slave object
    c['slaves'].append(
        BuildSlave(host, secret, **slave_params))

# 'slavePortnum' defines the TCP port to listen on for connections
#  from slaves.  The default is 9989. This must match the value
#  configured into the buildslaves (with their --master option)

c['slavePortnum'] = configs['global'].get('slavePortnum',9989)

####### CHANGESOURCES

# the 'change_source' setting tells the buildmaster how it should find
# out about source code changes.  Here we poll the configured branch
# of the configured git repo every 5 minutes note: there can be only
# one GitPoller pointing at a given repository

# a 'revlink' param in a change_source is used to generate a URL to a
# commit
#
# http://docs.buildbot.net/latest/manual/cfg-global.html#cfg-revlink
revlinks = {}
def add_revlink(remote, revlink):
    revlinks[remote] = revlink
    if debug:
        print "Added revlink '%s' -> \n    '%s'" % (remote,revlink)

def revlink_callback(revision, repository):
    if revlinks.has_key(repository):
        return revlinks[repository] % revision
    else:
        return None
c['revlink'] = revlink_callback

from buildbot.changes.gitpoller import GitPoller
from buildbot.changes.pb import PBChangeSource
for (csname,csconfig) in configs['change_source'].items():
    if debug:
        print ("Adding changesource config '%s'" % csname)
    cstype = csconfig.pop('type','(type not specified)')
    if cstype == 'poller':
        # 'repourl' is not a kwarg in buildbot 0.8.6
        repourl = csconfig.pop('repourl')
        c['change_source'].append(GitPoller(repourl, **csconfig))
        if debug:
            print ('    ' + '\n    '.join(['='.join((i[0],str(i[1])))
                                           for i in csconfig.items()]))
    elif cstype == 'PBChangeSource':
        # grab the password from the 'auth' dict
        csconfig['passwd'] = configs['auth'][csconfig['user']]
        c['change_source'].append(PBChangeSource(**csconfig))
        if debug:
            print ('    user: %s; passwd: %s[...]' % \
                       (csconfig['user'],
                        csconfig['passwd'][:3]))
    elif cstype == 'multi-multi-git-poller':
        # Really a PBChangeSource with a post-receive.py set to run
        # out of cron
        
        # set up revlinks
        for (key,val) in csconfig.pop('git-repos').items():
            if val.has_key('revlink'):
                add_revlink(val['local-remote'],val['revlink'])
            
        # grab the password from the 'auth' dict
        csconfig['passwd'] = configs['auth'][csconfig['user']]
        c['change_source'].append(PBChangeSource(**csconfig))
        if debug:
            print ('    user: %s; passwd: %s[...]' % \
                       (csconfig['user'],
                        csconfig['passwd'][:3]))
    else:
        print ("Error:  Unknown poller type in config:  %s" % cstype)
        raise

####### BUILDFACTORIES

# Build factories tell Buildbot how to perform a build:
#
# what steps, and which slaves can execute them.  Note that any
# particular build will only take place on one slave.

from buildbot.process.factory import BuildFactory
from buildbot.steps.source.git import Git
from buildbot.steps.shell import ShellCommand
from buildbot.steps.master import MasterShellCommand
from buildbot.steps.transfer import FileDownload
from buildbot.process.properties import Property
from buildbot.steps.trigger import Trigger
from buildbot.status.builder import SKIPPED

def prop_dict(properties):
    '''
    Build dict of properties with name as key and 'Property()' as value
    http://docs.buildbot.net/latest/manual/cfg-properties.html#property
    '''
    res = {}
    for property in properties:
        res[property] = Property(property)
    return res

def match_build_distro_arch(selectors,negate=False):
    def callback(step):
        # return True if the step and build share the same distro + arch
        res = True
        buildprops = step.build.getProperties()
        if buildprops.getProperty('distro',None) != selectors['distro'] or \
                buildprops.getProperty('arch',None) != selectors['arch']:
            res = False
        if negate:  return not res
        return res
    return callback

# Read build factories from config
factories = {}
for (bfname,bfconf) in configs['buildfactories'].items():
    if debug:
        print "Adding factory %s" % bfname
    bf = factories[bfname] = BuildFactory()
    # First steps: copy files
    for file in bfconf.get('copy-files',[]):
        if debug:
            print "    Copy file '%s'" % file
        bf.addStep(FileDownload(mastersrc=file,
                                slavedest=file))
    
    # Now process each step
    for stepconf in bfconf['steps']:
        # Gather configuration
        steptype = stepconf.pop('type','script')
        stepargs = {
            'haltOnFailure' : True }
        stepargs.update(stepconf)

        # Replace a doStepIf key with a function
        if stepargs.has_key('doStepIf'):
            func_name = stepargs.pop('doStepIf')
            if func_name == 'match_build_distro_arch':
                func = match_build_distro_arch
            else:
                raise Exception ("No such doStepIf function: %s" % func_name)
        if stepargs.has_key('selectors'):
            stepargs['doStepIf'] = func(stepargs.get('selectors',{}))
            stepargs['hideStepIf'] = lambda result, s: result==SKIPPED

        stepargs.pop('selectors',None)

        if debug:
            print "    Adding step '%s', type '%s', workdir '%s'" % \
                (stepargs['name'], steptype,
                 stepargs.get('workdir','<default>'))

        if steptype == 'source.git':
            # Pull from git
            if debug:
                print "      Repo: %s" % stepargs['repourl']
            bf.addStep(Git(**stepargs))

        elif steptype == 'script':
            # Run 'buildsteps.sh'

            # Any key/value pairs in the global 'env' dict
            # will show up as buildsteps.sh environment variables.
            #
            # Any property names in the 'env-properties' list will
            # also show up as environment variables with values filled
            # out.
            stepargs.setdefault('env',{}).update(
                configs['global'].get('env',{}))
            stepargs['env'].update(
                prop_dict(configs['global'].get('env-properties',[])))

            # Set up the buildsteps.sh command
            stepargs['command'] = [ "/bin/bash", "-xe",
                                    "./buildsteps.sh",
                                    stepargs['name'] ]

            # If the 'server-side' key is 'True', run the script on
            # the server; otherwise, run on the slave (default).
            if stepargs.pop('server-side',False):
                bf.addStep(MasterShellCommand(**stepargs))
            else:
                bf.addStep(ShellCommand(**stepargs))

        elif steptype == 'trigger':
            if debug:
                print "      Schedulers: %s" % \
                    ', '.join(stepargs['schedulerNames'])
            if stepargs.has_key('properties'):
                # Trigger schedulers have set_properties and copy_properties
                stepargs['set_properties'] = stepargs.pop('properties')
            bf.addStep(Trigger(**stepargs))

        else:
            raise Exception("Unknown build step type '%s'" % steptype)

####### BUILDERS

# finally, define builders. Each associates a buildfactory with one or
# more buildslaves.
#
# note: category= is used to segregate builders still in test from
#                 production builders haven't used this yet
#
# note: can't define "future" builders; seems to give buildbot a
# tummyache
#
# note: can reduce length of buildslave dirs by adding
# "builddir="<shortname>" after "name=" on each BuilderConfig

from buildbot.config import BuilderConfig

for (buildername,builderconfig_raw) in configs['builders'].items():

    # Merge default parameters
    builderconfig = builder_defaults.copy()
    builderconfig.update(builderconfig_raw)

    # filter list of slaves by class
    slavenames = []
    for (slavename,slaveconfig) in configs['slaves'].items():
        # Check each 'selectors' key/value pair matches
        match = True
        for (key,value) in builderconfig.get('selectors',{}).items():
            if not slaveconfig['selectors'].has_key(key):
                match = False
                break
            if not isinstance(slaveconfig['selectors'][key], list) and \
                    slaveconfig['selectors'][key] != value:
                match = False
                break
            if isinstance(slaveconfig['selectors'][key], list) and \
                    value not in slaveconfig['selectors'][key]:
                match = False
                break
        # Add matching slaves' names to list
        if match:
            slavenames.append(slavename)

    # Don't create builders for an empty slave list
    if not slavenames:
        # Remove the builder so it doesn't end up in a scheduler below
        configs['builders'].pop(buildername)

        print ("builder '%s': No slaves; removing from config" %
               buildername)
        continue

    # Set builder priority (as a property), default 50
    properties = builderconfig.get('properties',{})
    properties['priority'] = builderconfig.get('priority',50)

    # Create builder config objects for the specified factory
    factory = factories[builderconfig['factory']]
    c['builders'].append(
        BuilderConfig(name=buildername,
                      slavenames=slavenames,
                      factory=factory,
                      properties=properties))

    if debug:
        print ("builder '%s', slaves:\n    %s" %
               (buildername, ', '.join(slavenames)))


# Build prioritization
#
# Builders should have a numerical 'priority', where a lower number is
# higher priority
# http://docs.buildbot.net/latest/manual/customization.html#builder-priority-functions

def prioritizeBuilders(buildmaster, builders):
    """Prioritize builders using numerical priority.  Lower numbers
    are higher priority."""
    builders.sort(key=lambda b: b.config.properties['priority'])

    return builders

c['prioritizeBuilders'] = prioritizeBuilders


####### SCHEDULERS

# Configure the Schedulers, which decide how to react to incoming
# changes.  In this version, just trigger a cycle of build and
# runtests on the branch.
#
# Note we also support forced builds.
#
# treeStableTimer determines how long after the last detected change
# the scheduler waits before triggering the builders.

import buildbot.schedulers.basic
import buildbot.schedulers.forcesched
import buildbot.schedulers.triggerable
from buildbot.changes.filter import ChangeFilter

buildschedulermap = {
    'AnyBranchScheduler' : buildbot.schedulers.basic.AnyBranchScheduler,
    'SingleBranchScheduler' : buildbot.schedulers.basic.SingleBranchScheduler,
    'ForceScheduler' : buildbot.schedulers.forcesched.ForceScheduler,
    'Triggerable' : buildbot.schedulers.triggerable.Triggerable,
    'Dependent' : buildbot.schedulers.basic.Dependent,
    }

import re
def changeset_file_regex_callback(regex,negate=False):
    '''
    Given a regex, return a callback that takes a change set obj, and
    if any of the change set files matches, return True, or if
    negate=True, return False
    '''
    r = re.compile(regex)
    def callback(change):
        ''' Return %s if any of 'change.files' matches regex '%s' ''' % \
            (not negate,regex)
        res = negate
        for path in change.files:
            if r.search(path): res = not negate
        return res
    return callback

import subprocess
def contains_commit_callback(revision):
    '''
    Given a revision, return a callback that returns True if the
    provided Change set is an ancestor

    Used as the 'filter_fn' in a 'contains_commit' ChangeFilter
    '''
    # this callback returns True if the change set is a descendent of
    # the specified revision
    def callback(change):
        ''' Return True if 'change' is an ancestor of commit %s ''' % revision

        # get the full SHA1 of the revision
        p = subprocess.Popen(["git",
                              "--git-dir", change.repository,
                              "rev-parse", revision],
                             stdout=subprocess.PIPE)
        ancestor = p.communicate()[0]
        if ancestor == '':
            print ("Error:  contains_commit filter revision '%s' unparsable" %
                   revision)
            raise


        # run 'git merge-base <ancestor> <revision>'
        p = subprocess.Popen(["git",
                              "--git-dir", change.repository,
                              "merge-base", ancestor, change.revision],
                             stdout=subprocess.PIPE)
        mergebase = p.communicate()[0]

        # if the merge base is the ancestor, then the change set is a
        # descendent
        return mergebase == ancestor

    return callback

# get builder defaults
builder_default_factory = builder_defaults.get('factory',None)

# A dict for easy lookup of upstream schedulers
scheduler_dict = {}

# process scheduler config list
#
# any Dependent schedulers must be process last, since those point to
# other schedulers
for (name,config) in sorted(
    configs['schedulers'].items(),
    key=lambda s: [0,1][s[1].get('class',None) == 'Dependent']):
    # Match up builderconfigs by matching type and other params

    # Init arg dict
    scheduler_args = { 'name' : name,
                       'builderNames' : []}

    if debug:
        print "Adding scheduler '%s', class %s" % \
            (name, config['class'])

    # Build list of matching builderconfigs
    for (bcname,bcconfig) in configs['builders'].items():

        # get the builder's factory
        factory = bcconfig.get("factory",builder_default_factory)

        # add to the list if factory and selectors match
        if config['builder_factory'] == factory and \
                config.get('selectors','') == bcconfig.get('selectors',''):
            if debug:
                print "    Adding builder %s to scheduler" % bcname
            scheduler_args['builderNames'].append(bcname)

    # Get the scheduler class
    scheduler_class = buildschedulermap[config['class']]

    # The 'Dependent' class needs the upstream scheduler object
    if config['class'] == 'Dependent':
        scheduler_args['upstream'] = scheduler_dict[config['upstream']]
        if debug:
            print "    upstream scheduler:  %s" % \
                scheduler_args['upstream'].name

    # Add a filter
    # http://docs.buildbot.net/latest/manual/cfg-schedulers.html#change-filters
    if config.has_key('change_filter'):
        filt = config['change_filter']
        if filt['type'] == 'contains_commit':
            scheduler_args['change_filter'] = ChangeFilter(
                filter_fn = contains_commit_callback(filt['commit']))
            if debug:
                print "    Filtering branches containing commit %s" % \
                    filt['commit']
        else:
            print ("Error:  unknown filter type '%s'" % filt['type'])
            raise

    # fileIsImportant:  check if the change set should trigger a build
    # http://docs.buildbot.net/latest/manual/cfg-schedulers.html
    if config.has_key('fileIsImportant'):
        fii = config['fileIsImportant']
        if fii['type'] == 'changeset_file_regex':
            scheduler_args['fileIsImportant'] = changeset_file_regex_callback(
                fii['regex'], fii.get('negate',False))
            if debug:
                print (
                    "    Trigger when a changed file %s regex '%s'" % \
                        (('matches','does not match')[fii.get('negate',False)],
                         fii['regex']))
        else:
            print ("Error:  unknown 'fileIsImportant' type '%s'" % fii['type'])
            raise

    # Add other params directly from config
    for p in ['treeStableTimer']:
        if config.has_key(p):
            scheduler_args[p] = config[p]

    # Create the scheduler object
    scheduler = scheduler_class(**scheduler_args)
    c['schedulers'].append(scheduler)
    scheduler_dict[name] = scheduler


####### STATUS TARGETS

# 'status' is a list of Status Targets. The results of each build will
# be pushed to these targets. buildbot/status/*.py has a variety to
# choose from, including web pages, email senders, and IRC bots.
#
# In this version, only WebStatus is used.
#
# note: the docs make me believe I can use categories= here but
#       checkconfig disagrees???
#
# note: adding "order_console_by_time=True" to WebStatus to make the
#       console view work (cf: trac.buildbot.net/wiki/FAQ) - sadly,
#       does nothing for forced builds but console view now displays
#       git change info...pretty cool!

from buildbot.status import html
from buildbot.status.web import authz, auth

if debug:
    print "Adding basic auth with users:  %s" % \
        ', '.join(configs['auth'].keys())

for (name,config) in configs['status'].items():
    if debug:
        print "Adding status page '%s', class %s" % \
            (name, config.get('class','WebStatus'))

    # Turn 'authz' attribute into an Authz object
    if config.has_key('authz'):
        authzconfig = config.pop('authz')
        authclass = authzconfig.pop('class','BasicAuth')
        if authzconfig.get('useHttpHeader') is True:
            if debug:
                print "   Authorization passed from reverse proxy"
        elif authclass == 'BasicAuth':
            # List of names/passwords
            if debug:
                print "   Authorizing user/password pairs in configuration"
            authzconfig['auth'] = auth.BasicAuth(configs['auth'].items())
        else:
            print "Unsupported auth class '%s'" % authclass
            sys.exit(1)
        
        config['authz'] = authz.Authz(**authzconfig)

    # Create the WebStatus UI object
    statusclass = config.pop('class','WebStatus')
    if statusclass == 'WebStatus':
        if debug:
            print "   Adding WebStatus object"
        c['status'].append(html.WebStatus(**config))
    else:
        print "Unsupported status class '%s'" % statusclass
        sys.exit(1)

####### PROJECT IDENTITY

c.update(configs['identity'])

####### DB URL

c['db'] = configs['db']
