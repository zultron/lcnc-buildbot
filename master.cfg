# ex: set syntax=python:					-*-python-*-

# This is the buildmaster config file for the Unified Build Candidate
# Project for LinuxCNC. It must be installed as 'master.cfg' in your
# buildmaster's base directory.
# 
# Author: Kent A Reed, based on master.cfg.sample file included in
# BuildBot distro
#
# Version 1 (I don't like 'point' versions for configuration files):
#
# In this version, everything is done explicitly. No cleverness with
# variables, builders, with Python scripts, with most anything. Mostly
# I ignored the "fleet" of predefined buildStep Classes/commands and
# used shell scripts.
#

####### VARIABLES

# Debug flag (True or False)
debug = True
if debug:
    from pprint import pprint

####### CONFIG

# Read in host and builder configuration from 'config.yaml'
#
# See 'config.yaml.sample' for notes about format
#
import os, yaml
try:
    basedir
    outside_buildbot = False
except:
    # basedir not defined; this script not called from buildbot
    basedir = os.path.dirname(os.path.realpath(__file__))
    outside_buildbot = True
configs = \
    yaml.load(open(os.path.join(basedir,'config.yaml'),'r').read())

# get defaults
builder_defaults = configs['builders'].pop('DEFAULT',{})
slave_defaults = configs['slaves'].pop("DEFAULT",{})


# Init the dictionary that the buildmaster pays attention to. We
# also use a shorter alias to save typing.

c = BuildmasterConfig = {
    'slaves' : [],
    'schedulers' : [],
    'change_source' : [],
    'builders' : [],
    'status' : [],
    }

# Set the umask
if configs['global'].has_key('umask'):
    if debug:
        print "Setting umask to %s" % oct(configs['global']['umask'])
    os.umask(configs['global']['umask'])

####### ENUMERATIONS

class Enumerations(object):

    def __init__(self,val):
        self.exclude = val.pop('exclude',[])
        self.val = val
        self.order = {}
        for (key,val) in self.val.items():
            self.order[key] = val.pop('order',None)
            if self.order[key] is None:
                # if no order specified, sort keys
                self.order[key] = sorted(val.keys())

    def get_enum(self,key):
        return self.expand_enum(self.val[key])

    def expand_enum(self,enum):
        res = {}
        # fill out 'update' keys
        if enum.has_key('update'):
            enum.update(self.get_enum(enum.pop('update')))
        # fill out the rest and return
        res.update(enum)
        return res

    def permutations(self,key,order=None):
        top = False
        if order is None:
            # temp copy of key order
            order = list(self.order[key])
            top = True
        val = self.val[key]
        enum_key = order.pop(0)
        if order:
            sub_p = self.permutations(key,order)
        else:
            sub_p = [{}]
        ps = []
        for i in self.get_enum(key)[enum_key]:
            for j in sub_p:
                p = { enum_key : i }
                if j: p.update(j)
                if not top or not self.is_excluded(key,p):
                    ps.append(p)
        return ps

    def is_excluded(self,key,p):
        format_str = '-'.join(['%(' + i + ')s' for i in self.order[key]])
        return format_str % p in self.exclude

    def expand_builders(self,builders):
        # return new dict of builders
        res = builders.copy()
        for name in builders:
            if not builders[name].has_key('enumerate'):
                # no enumeration; do nothing
                continue
            conf = res.pop(name)
            for p in self.permutations(conf.pop('enumerate')):
                newname = name % p
                newconf = conf.copy()
                newconf.setdefault('properties',{}).update(p)
                if newconf.has_key('slaveclasses'):
                    newconf['slaveclasses'] = newconf['slaveclasses'].copy()
                    for key in newconf['slaveclasses']:
                        newconf['slaveclasses'][key] = \
                            newconf['slaveclasses'][key] % p
                res[newname] = newconf
        return res

enumerations = Enumerations(configs.pop('enumerations',{}))

configs['builders'] = enumerations.expand_builders(configs['builders'])

####### BUILDSLAVES

# The 'slaves' list defines the set of recognized buildslaves. Each
# element is a BuildSlave object, specifying a unique slave name and
# password.  The same slave name and password must be configured on
# the slave.
#
# note: max_builds= is used to limit the cpu burden. The host may be
# capable of more
#
# note: no harm to define some "future" slaves which don't exist yet

from buildbot.buildslave import BuildSlave
for (host, params) in configs['slaves'].items():

    # Copy the slave_defaults dict and merge parameters
    slave_params = slave_defaults.copy()
    slave_params.update(params)

    # 'password' is a positional parameter; remove from params dict
    secret = slave_params.pop('secret',None)

    # remove 'selectors' used to match builders
    slave_params.pop('selectors',None)

    if debug:
        print("Adding slave, name='%s', secret='%s[...]'" % (host,secret[:3]))

    # Create the build slave object
    c['slaves'].append(
        BuildSlave(host, secret, **slave_params))

# 'slavePortnum' defines the TCP port to listen on for connections
#  from slaves.  The default is 9989. This must match the value
#  configured into the buildslaves (with their --master option)

c['slavePortnum'] = configs['global'].get('slavePortnum',9989)

####### CHANGESOURCES

# the 'change_source' setting tells the buildmaster how it should find
# out about source code changes.  Here we poll the configured branch
# of the configured git repo every 5 minutes note: there can be only
# one GitPoller pointing at a given repository

# a 'revlink' param in a change_source is used to generate a URL to a
# commit
#
# http://docs.buildbot.net/latest/manual/cfg-global.html#cfg-revlink
revlinks = {}
def add_revlink(remote, revlink):
    revlinks[remote] = revlink
    if debug:
        print "Added revlink '%s' -> \n    '%s'" % (remote,revlink)

def revlink_callback(revision, repository):
    if revlinks.has_key(repository):
        return revlinks[repository] % revision
    else:
        return None
c['revlink'] = revlink_callback

from buildbot.changes.gitpoller import GitPoller
from buildbot.changes.pb import PBChangeSource
for (csname,csconfig) in configs['change_source'].items():
    if debug:
        print ("Adding changesource config '%s'" % csname)
    cstype = csconfig.pop('type','(type not specified)')
    if cstype == 'poller':
        # 'repourl' is not a kwarg in buildbot 0.8.6
        repourl = csconfig.pop('repourl')
        c['change_source'].append(GitPoller(repourl, **csconfig))
        if debug:
            print ('    ' + '\n    '.join(['='.join((i[0],str(i[1])))
                                           for i in csconfig.items()]))
    elif cstype == 'PBChangeSource':
        # grab the password from the 'auth' dict
        csconfig['passwd'] = configs['auth'][csconfig['user']]
        c['change_source'].append(PBChangeSource(**csconfig))
        if debug:
            print ('    user: %s; passwd: %s[...]' % \
                       (csconfig['user'],
                        csconfig['passwd'][:3]))
    elif cstype == 'multi-multi-git-poller':
        # Really a PBChangeSource with a post-receive.py set to run
        # out of cron
        
        # set up revlinks
        for (key,val) in csconfig.pop('git-repos').items():
            if val.has_key('revlink'):
                add_revlink(val['local-remote'],val['revlink'])
            
        # grab the password from the 'auth' dict
        csconfig['passwd'] = configs['auth'][csconfig['user']]
        c['change_source'].append(PBChangeSource(**csconfig))
        if debug:
            print ('    user: %s; passwd: %s[...]' % \
                       (csconfig['user'],
                        csconfig['passwd'][:3]))
    else:
        print ("Error:  Unknown poller type in config:  %s" % cstype)
        raise

####### BUILDFACTORIES

# Build factories tell Buildbot how to perform a build:
#
# what steps, and which slaves can execute them.  Note that any
# particular build will only take place on one slave.

from buildbot.process.factory import BuildFactory
from buildbot.steps.source.git import Git
from buildbot.steps.shell import ShellCommand
from buildbot.steps.master import MasterShellCommand
from buildbot.steps.transfer import FileDownload
from buildbot.process.properties import Property
from buildbot.steps.trigger import Trigger

def prop_dict(properties):
    '''
    Build dict of properties with name as key and 'Property()' as value
    http://docs.buildbot.net/latest/manual/cfg-properties.html#property
    '''
    res = {}
    for property in properties:
        res[property] = Property(property)
    return res

# Read build factories from config
factories = {}
for (bfname,bfconf) in configs['buildfactories'].items():
    if debug:
        print "Adding factory %s" % bfname
    bf = factories[bfname] = BuildFactory()
    # First step will always be to grab the buildsteps script, if
    # configured; this needs to be forced in case of updates
    if bfconf.get('buildsteps-script',None) is not None:
        if debug:
            print "    Adding buildsteps step, source=%s" % \
                bfconf['buildsteps-script']
        bf.addStep(FileDownload(mastersrc=bfconf['buildsteps-script'],
                                slavedest="buildsteps.sh"))
    
    # Now process each step
    for stepconf in bfconf['steps']:
        # Gather configuration
        steptype = stepconf.pop('type','script')
        stepargs = {
            'haltOnFailure' : True }
        stepargs.update(stepconf)

        if debug:
            print "    Adding step '%s', type '%s', workdir '%s'" % \
                (stepargs['name'], steptype,
                 stepargs.get('workdir','<default>'))

        if steptype == 'source.git':
            # Pull from git
            if debug:
                print "      Repo: %s" % stepargs['repourl']
            bf.addStep(Git(**stepargs))

        elif steptype == 'script':
            # Run 'buildsteps.sh'

            # Any key/value pairs in the global 'env' dict
            # will show up as buildsteps.sh environment variables.
            #
            # Any property names in the 'env-properties' list will
            # also show up as environment variables with values filled
            # out.
            stepargs.setdefault('env',{}).update(
                configs['global'].get('env',{}))
            stepargs['env'].update(
                prop_dict(configs['global'].get('env-properties',[])))

            # Set up the buildsteps.sh command
            stepargs['command'] = [ "/bin/bash", "-xe",
                                    "./buildsteps.sh",
                                    stepargs['name'] ]

            # If the 'server-side' key is 'True', run the script on
            # the server; otherwise, run on the slave (default).
            if stepargs.pop('server-side',False):
                bf.addStep(MasterShellCommand(**stepargs))
            else:
                bf.addStep(ShellCommand(**stepargs))

        elif steptype == 'trigger':
            if debug:
                print "      Schedulers: %s" % \
                    ', '.join(stepargs['schedulerNames'])
            bf.addStep(Trigger(**stepargs))

        else:
            raise Exception("Unknown build step type '%s'" % steptype)

####### BUILDERS

# finally, define builders. Each associates a buildfactory with one or
# more buildslaves.
#
# note: category= is used to segregate builders still in test from
#                 production builders haven't used this yet
#
# note: can't define "future" builders; seems to give buildbot a
# tummyache
#
# note: can reduce length of buildslave dirs by adding
# "builddir="<shortname>" after "name=" on each BuilderConfig

from buildbot.config import BuilderConfig

for (buildername,builderconfig_raw) in configs['builders'].items():

    # Merge default parameters
    builderconfig = builder_defaults.copy()
    builderconfig.update(builderconfig_raw)

    # filter list of slaves by class
    slavenames = []
    for (slavename,slaveconfig) in configs['slaves'].items():
        # Check each 'slaveclasses' key/value pair matches
        match = True
        for (key,value) in builderconfig.get('slaveclasses',{}).items():
            if not slaveconfig['selectors'].has_key(key):
                match = False
                break
            if not isinstance(slaveconfig['selectors'][key], list) and \
                    slaveconfig['selectors'][key] != value:
                match = False
                break
            if isinstance(slaveconfig['selectors'][key], list) and \
                    value not in slaveconfig['selectors'][key]:
                match = False
                break
        # Add matching slaves' names to list
        if match:
            slavenames.append(slavename)

    # Don't create builders for an empty slave list
    if not slavenames:
        # Remove the builder so it doesn't end up in a scheduler below
        configs['builders'].pop(buildername)

        print ("builder '%s': No slaves; removing from config" %
               buildername)
        continue

    # Set builder priority (as a property), default 50
    properties = builderconfig.get('properties',{})
    properties['priority'] = builderconfig.get('priority',50)

    # Create builder config objects for the specified factory
    factory = factories[builderconfig['factory']]
    c['builders'].append(
        BuilderConfig(name=buildername,
                      slavenames=slavenames,
                      factory=factory,
                      properties=properties))

    if debug:
        print ("builder '%s', slaves:\n    %s" %
               (buildername, ', '.join(slavenames)))


# Build prioritization
#
# Builders should have a numerical 'priority', where a lower number is
# higher priority
# http://docs.buildbot.net/latest/manual/customization.html#builder-priority-functions

def prioritizeBuilders(buildmaster, builders):
    """Prioritize builders using numerical priority.  Lower numbers
    are higher priority."""
    builders.sort(key=lambda b: b.config.properties['priority'])

    return builders

c['prioritizeBuilders'] = prioritizeBuilders


####### SCHEDULERS

# Configure the Schedulers, which decide how to react to incoming
# changes.  In this version, just trigger a cycle of build and
# runtests on the branch.
#
# Note we also support forced builds.
#
# treeStableTimer determines how long after the last detected change
# the scheduler waits before triggering the builders.

import buildbot.schedulers.basic
import buildbot.schedulers.forcesched
import buildbot.schedulers.triggerable
from buildbot.changes.filter import ChangeFilter

buildschedulermap = {
    'AnyBranchScheduler' : buildbot.schedulers.basic.AnyBranchScheduler,
    'SingleBranchScheduler' : buildbot.schedulers.basic.SingleBranchScheduler,
    'ForceScheduler' : buildbot.schedulers.forcesched.ForceScheduler,
    'Triggerable' : buildbot.schedulers.triggerable.Triggerable,
    'Dependent' : buildbot.schedulers.basic.Dependent,
    }

import subprocess
def contains_commit_callback(revision):
    '''
    Given a revision, return a callback that returns True if the
    provided Change set is an ancestor

    Used as the 'filter_fn' in a 'contains_commit' ChangeFilter
    '''
    # this callback returns True if the change set is a descendent of
    # the specified revision
    def callback(change):
        ''' Return True if 'change' is an ancestor of commit %s ''' % revision

        # get the full SHA1 of the revision
        p = subprocess.Popen(["git",
                              "--git-dir", change.repository,
                              "rev-parse", revision],
                             stdout=subprocess.PIPE)
        ancestor = p.communicate()[0]
        if ancestor == '':
            print ("Error:  contains_commit filter revision '%s' unparsable" %
                   revision)
            raise


        # run 'git merge-base <ancestor> <revision>'
        p = subprocess.Popen(["git",
                              "--git-dir", change.repository,
                              "merge-base", ancestor, change.revision],
                             stdout=subprocess.PIPE)
        mergebase = p.communicate()[0]

        # if the merge base is the ancestor, then the change set is a
        # descendent
        return mergebase == ancestor

    return callback

# get builder defaults
builder_default_factory = builder_defaults.get('factory',None)

# A dict for easy lookup of upstream schedulers
scheduler_dict = {}

# process scheduler config list
#
# any Dependent schedulers must be process last, since those point to
# other schedulers
for (name,config) in sorted(
    configs['schedulers'].items(),
    key=lambda s: [0,1][s[1].get('class',None) == 'Dependent']):
    # Match up builderconfigs by matching type and other params

    # Init arg dict
    scheduler_args = { 'name' : name,
                       'builderNames' : []}

    if debug:
        print "Adding scheduler '%s', class %s" % \
            (name, config['class'])

    # Build list of matching builderconfigs
    for (bcname,bcconfig) in configs['builders'].items():

        # get the builder's factory
        factory = bcconfig.get("factory",builder_default_factory)

        # add to the list if class matches
        if config['builder_factory'] == factory:
            if debug:
                print "    Adding builder %s to scheduler" % bcname
            scheduler_args['builderNames'].append(bcname)

    # Get the scheduler class
    scheduler_class = buildschedulermap[config['class']]

    # The 'Dependent' class needs the upstream scheduler object
    if config['class'] == 'Dependent':
        scheduler_args['upstream'] = scheduler_dict[config['upstream']]
        if debug:
            print "    upstream scheduler:  %s" % \
                scheduler_args['upstream'].name

    # Add a filter
    # http://docs.buildbot.net/latest/manual/cfg-schedulers.html#change-filters
    if config.has_key('change_filter'):
        filt = config['change_filter']
        if filt['type'] == 'contains_commit':
            scheduler_args['change_filter'] = ChangeFilter(
                filter_fn = contains_commit_callback(filt['commit']))
            if debug:
                print "    Filtering branches containing commit %s" % \
                    filt['commit']
        else:
            print ("Error:  unknown filter type '%s'" % filt['type'])
            raise

    # Add other params directly from config
    for p in ['treeStableTimer']:
        if config.has_key(p):
            scheduler_args[p] = config[p]

    # Create the scheduler object
    scheduler = scheduler_class(**scheduler_args)
    c['schedulers'].append(scheduler)
    scheduler_dict[name] = scheduler


####### STATUS TARGETS

# 'status' is a list of Status Targets. The results of each build will
# be pushed to these targets. buildbot/status/*.py has a variety to
# choose from, including web pages, email senders, and IRC bots.
#
# In this version, only WebStatus is used.
#
# note: the docs make me believe I can use categories= here but
#       checkconfig disagrees???
#
# note: adding "order_console_by_time=True" to WebStatus to make the
#       console view work (cf: trac.buildbot.net/wiki/FAQ) - sadly,
#       does nothing for forced builds but console view now displays
#       git change info...pretty cool!

from buildbot.status import html
from buildbot.status.web import authz, auth

if debug:
    print "Adding basic auth with users:  %s" % \
        ', '.join(configs['auth'].keys())

for (name,config) in configs['status'].items():
    if debug:
        print "Adding status page '%s', class %s" % \
            (name, config.get('class','WebStatus'))

    # Turn 'authz' attribute into an Authz object
    if config.has_key('authz'):
        authzconfig = config.pop('authz')
        authclass = authzconfig.pop('class','BasicAuth')
        if authzconfig.get('useHttpHeader') is True:
            if debug:
                print "   Authorization passed from reverse proxy"
        elif authclass == 'BasicAuth':
            # List of names/passwords
            if debug:
                print "   Authorizing user/password pairs in configuration"
            authzconfig['auth'] = auth.BasicAuth(configs['auth'].items())
        else:
            print "Unsupported auth class '%s'" % authclass
            sys.exit(1)
        
        config['authz'] = authz.Authz(**authzconfig)

    # Create the WebStatus UI object
    statusclass = config.pop('class','WebStatus')
    if statusclass == 'WebStatus':
        if debug:
            print "   Adding WebStatus object"
        c['status'].append(html.WebStatus(**config))
    else:
        print "Unsupported status class '%s'" % statusclass
        sys.exit(1)

####### PROJECT IDENTITY

c.update(configs['identity'])

####### DB URL

c['db'] = configs['db']
